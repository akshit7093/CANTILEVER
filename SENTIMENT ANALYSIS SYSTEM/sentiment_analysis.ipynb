{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshit7093/CANTILEVER/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_6BvPrWp56u",
        "outputId": "b7823280-d36f-43ae-9094-50eaad79b47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMUveS2CEE1s",
        "outputId": "0ab35a05-836e-434d-a9ba-85cede87fe5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3xVSK1dAeTf"
      },
      "source": [
        "**GPT**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkdprNo4AZQs"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEetScv2Ap1F",
        "outputId": "08ec8c4d-fe74-403b-8514-3b8afea2f8e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOdr6XScBl3v"
      },
      "outputs": [],
      "source": [
        "# Load the IMDB dataset\n",
        "def load_data():\n",
        "    df = pd.read_csv('IMDB Dataset.csv')\n",
        "    df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    return df\n",
        "\n",
        "df = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WikAF36YBzPG"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return ' '.join([lemmatizer.lemmatize(token) for token in tokens if token.isalnum()])\n",
        "\n",
        "df['processed_text'] = df['review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZhVhnBFCHt4",
        "outputId": "4029e92f-4e37-4554-8b0d-8732395551ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    one of the other reviewer ha mentioned that af...\n",
            "1    a wonderful little production br br the filmin...\n",
            "2    i thought this wa a wonderful way to spend tim...\n",
            "3    basically there a family where a little boy ja...\n",
            "4    petter mattei love in the time of money is a v...\n",
            "Name: processed_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['processed_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO_zwAZGCT9k",
        "outputId": "d2d809f9-3c62-446d-ef8a-a4e5153b5ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of feature matrix: (50000, 5000)\n",
            "Shape of target vector: (50000,)\n",
            "Training set shape: (40000, 5000)\n",
            "Testing set shape: (10000, 5000)\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 9s 8ms/step - loss: 0.3737 - accuracy: 0.8404 - val_loss: 0.2706 - val_accuracy: 0.8859\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2472 - accuracy: 0.9054 - val_loss: 0.2761 - val_accuracy: 0.8838\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2082 - accuracy: 0.9227 - val_loss: 0.2964 - val_accuracy: 0.8801\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1722 - accuracy: 0.9384 - val_loss: 0.3321 - val_accuracy: 0.8775\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1410 - accuracy: 0.9508 - val_loss: 0.3486 - val_accuracy: 0.8780\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1142 - accuracy: 0.9617 - val_loss: 0.3793 - val_accuracy: 0.8749\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0911 - accuracy: 0.9702 - val_loss: 0.4328 - val_accuracy: 0.8751\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0752 - accuracy: 0.9747 - val_loss: 0.4915 - val_accuracy: 0.8741\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0663 - accuracy: 0.9770 - val_loss: 0.4982 - val_accuracy: 0.8730\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0603 - accuracy: 0.9797 - val_loss: 0.5225 - val_accuracy: 0.8725\n",
            "Test Accuracy: 0.8755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 152ms/step\n",
            "Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df['processed_text']).toarray()\n",
        "y = df['sentiment'].values\n",
        "\n",
        "print(\"Shape of feature matrix:\", X.shape)\n",
        "print(\"Shape of target vector:\", y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(5000,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "model.save('sentiment_model.h5')\n",
        "# joblib.dump(tfidf, 'tfidf_vectorizer.joblib')\n",
        "\n",
        "\n",
        "def predict_sentiment(review):\n",
        "    processed = preprocess_text(review)\n",
        "    features = tfidf.transform([processed]).toarray()\n",
        "    prediction = model.predict(features)[0][0]\n",
        "    return \"Positive\" if prediction > 0.5 else \"Negative\"\n",
        "\n",
        "# Test the function\n",
        "new_review = \"This movie was fantastic! I loved every minute of it.\"\n",
        "print(f\"Sentiment: {predict_sentiment(new_review)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odPzlrkIEvLy",
        "outputId": "74b0f57d-ea81-47df-f6ab-57907a65bc60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "new_review = \"actors were so over dramatic and over acting \"\n",
        "print(f\"Sentiment: {predict_sentiment(new_review)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuAdwI8FN/GJ1P3E416mGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}